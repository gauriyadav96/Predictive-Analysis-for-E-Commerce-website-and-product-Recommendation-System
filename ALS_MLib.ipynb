{"cells":[{"cell_type":"code","source":["from pyspark.ml.recommendation import ALS\nfrom pyspark.ml.evaluation import RegressionEvaluator\nfrom pyspark.ml.tuning import TrainValidationSplit, ParamGridBuilder\nfrom pyspark.sql.functions import udf, col, first, when\nfrom pyspark.sql.types import IntegerType\nfrom pyspark.sql import Row, SparkSession\nfrom pyspark.sql.types import *\nimport numpy as np\nimport pandas as pd\nfrom pyspark.sql.functions import udf\nfrom pandas import pivot_table"],"metadata":{},"outputs":[],"execution_count":1},{"cell_type":"code","source":["sc = StructType([ \n                     StructField(\"id\",IntegerType(),True),\n                     StructField(\"Brand\",StringType(),True),\n                     StructField(\"Categories\",StringType(),True),\n                     StructField(\"dateAdded\",StringType(),True),\n                     StructField(\"dateUpdated\",StringType(),True),\n                     StructField(\"ean\",IntegerType(),True),\n                     StructField(\"keys\",StringType(),True),\n                     StructField(\"manufacturer\",StringType(),True),\n                     StructField(\"manufacturerNumber\",IntegerType(),True),\n                     StructField(\"manufacturerName\",StringType(),True),\n                     StructField(\"reviewDate\",StringType(), True),\n                     StructField(\"reviewDateAdded\",StringType(),True),\n                     StructField(\"dateSeen\",StringType(),True),\n                     StructField(\"didPurchase\",StringType(),True),\n                     StructField(\"doRecommended\",StringType(),True),\n                     StructField(\"reviewId\",StringType(),True),\n                     StructField(\"reviewHelpful\",StringType(),True),\n                     StructField(\"rating\",IntegerType(),True),\n                     StructField(\"sourceURL\",StringType(),True),                         \n                     StructField(\"text\",StringType(),True),       \n                     StructField(\"title\",StringType(),True),               \n                     StructField(\"userCity\",StringType(),True),\n                     StructField(\"userProvince\",StringType(),True),\n                     StructField(\"username\",StringType(),True),\n                     StructField(\"upc\",IntegerType(),True) ]) "],"metadata":{},"outputs":[],"execution_count":2},{"cell_type":"code","source":["spark_df = sqlContext.read.format('csv').options(header='true', inferSchema = True).load('/FileStore/tables/ecommerce.csv')\n#spark_df = spark.read.csv('/FileStore/tables/', header=True, schema=sc);\n\ndata = pd.read_csv('/dbfs/FileStore/tables/ecommerce.csv', encoding = \"ISO-8859-1\")\n\n#data = spark.read.csv('/FileStore/tables/newdata.csv', header=True, schema=sc)"],"metadata":{},"outputs":[],"execution_count":3},{"cell_type":"code","source":["display(spark_df)"],"metadata":{},"outputs":[],"execution_count":4},{"cell_type":"code","source":["print(spark_df)"],"metadata":{},"outputs":[],"execution_count":5},{"cell_type":"code","source":["# didPurchase           38845\n# doRecommend           10571\n# reviews_id            38845\n# reviews.numHelpful    38496\n# rating                    0\n# sourceURLs                0\n# text                     34\n# title                   473\n# userCity                  0\n# userProvince          70554\n# username                 54\n# upc                       2\n# spark_df = spark_df.drop('ean')\n# spark_df = spark_df.drop('manufacturerNumber')\n# spark_df = spark_df.drop('didPurchase')\n# spark_df = spark_df.drop('doRecommend')\n# spark_df = spark_df.drop('reviews_id')\n# spark_df = spark_df.drop('reviews.numHelpful')\n# spark_df = spark_df.drop('title')\n# spark_df = spark_df.drop('text')\n# spark_df = spark_df.drop('userProvince')\n# spark_df = spark_df.drop('dateAdded.1')\n# spark_df = spark_df.drop('reviews.date')\n# spark_df = spark_df.drop('upc')"],"metadata":{},"outputs":[],"execution_count":6},{"cell_type":"code","source":["spark_df=spark_df.withColumn(\"rating\", spark_df[\"rating\"].cast(IntegerType()))\n"],"metadata":{},"outputs":[],"execution_count":7},{"cell_type":"code","source":["spark_df = spark_df[['rating','username','id']]"],"metadata":{},"outputs":[],"execution_count":8},{"cell_type":"code","source":["spark_df = spark_df.fillna({'rating':'3'})"],"metadata":{},"outputs":[],"execution_count":9},{"cell_type":"code","source":["spark_df.printSchema()"],"metadata":{},"outputs":[],"execution_count":10},{"cell_type":"code","source":["df_pandas = spark_df.toPandas()"],"metadata":{},"outputs":[],"execution_count":11},{"cell_type":"code","source":["# this will give the 9 digit hash of given string\n# and it, most definitely, will be unique for different values and same for same values\ndef get_hash(x):\n  return abs(hash(x)) % 10**9\ndf_pandas['username'] = df_pandas['username'].apply(get_hash)\ndf_pandas['id'] = df_pandas['id'].apply(get_hash)\n# you can do the same thing for any column you want without ever worrying about \n# getting duplicate entries"],"metadata":{},"outputs":[],"execution_count":12},{"cell_type":"code","source":["# here you will see that 1 and 2 has the same values it's because both \n# of their username strings were same\ndf_pandas.head()['username']"],"metadata":{},"outputs":[],"execution_count":13},{"cell_type":"code","source":["(df_pandas['rating'])\n"],"metadata":{},"outputs":[],"execution_count":14},{"cell_type":"code","source":["##ALS takes as user preference by item as an input and generates an item for a\n##user. We have used userId, rating and customerId for recommendation of product in\n## ALS Algorithm. ALS algorithm considers similarity between user’s taste for\n## product as well as user’s past purchases.\n"],"metadata":{},"outputs":[],"execution_count":15},{"cell_type":"code","source":["table = df_pandas.pivot_table(index='username', values='rating', columns='id', aggfunc=np.mean)\ntable = table.fillna(0)\nstockCodes = table.columns[:]\nprint(len(stockCodes))\nprint((table.columns))\nstockCode_list = data['id'].unique()\nprint(len(stockCode_list))\nuser_rating_array = []\n\nproduct_list = []\n# create a list of product StockCodes\nfor index, row in table.iterrows():\n  for name, value in row.iteritems():\n    product_list.append(name)\n    print(name)\n  break\n\nprogress = 0\n# this will take some time\nfor index, row in table.iterrows():\n  customer_id = index\n  product_id = 0\n  for name, value in row.iteritems():\n    if int(value) > 0:\n      rating_row_array = (int(customer_id), int(product_id), int(value))\n      user_rating_array.append(rating_row_array)\n    product_id += 1\n  progress += 1\n  \nprint(user_rating_array)\n#   bar.update(progress)\n# bar.finish()"],"metadata":{},"outputs":[],"execution_count":16},{"cell_type":"code","source":["df_user_rating = pd.DataFrame(user_rating_array, columns=['user', 'product', 'rating'])\nprint(\"pandas dataframe created\")\ndf_user_rating.to_csv('/dbfs/FileStore/tables/user_rating.csv')"],"metadata":{},"outputs":[],"execution_count":17},{"cell_type":"code","source":["### Creating the final csv userr_rating which have userid, rating and productId for ALS Algorithm"],"metadata":{},"outputs":[],"execution_count":18},{"cell_type":"code","source":["print(\"creating user_ratings dataframe\")\n# user_ratings = sqlContext.createDataFrame(user_rating_array, ['user', 'product', 'rating']).collect()\nuser_ratings = sqlContext.read.format('csv').options(header='true', inferSchema='true').load('/FileStore/tables/user_rating.csv')"],"metadata":{},"outputs":[],"execution_count":19},{"cell_type":"code","source":["user_ratings.show()"],"metadata":{},"outputs":[],"execution_count":20},{"cell_type":"code","source":["## Diving the data into training and test\n## Using recommendForAllUsers method of ALS Algorithm, products are generated\n## which are recommended to each user. Using recommendForAllItems method\n##we get user recommendation for each product. "],"metadata":{},"outputs":[],"execution_count":21},{"cell_type":"code","source":["(training, test) = user_ratings.randomSplit([0.8, 0.2])\ntraining=training.withColumn(\"product\", training[\"product\"].cast(IntegerType()))\n\ntest=test.withColumn(\"product\", test[\"product\"].cast(IntegerType()))\n\n# Build the recommendation model using ALS on the training data\n# Note we set cold start strategy to 'drop' to ensure we don't get NaN evaluation metrics\nals = ALS(rank = 10, maxIter=30, regParam=0.3, userCol=\"user\", itemCol=\"product\", ratingCol=\"rating\",\n          coldStartStrategy=\"drop\")\nmodel = als.fit(training)\n\n# Evaluate the model by computing the RMSE on the test data\npredictions = model.transform(test)\nevaluator = RegressionEvaluator(metricName=\"rmse\", labelCol=\"rating\",\n                                predictionCol=\"prediction\")\nrmse = evaluator.evaluate(predictions)\nprint(\"Root-mean-square error = \" + str(rmse))\n\n# Generate top 10 product recommendations for each user\nuserRecs = model.recommendForAllUsers(10)\n# Generate top 10 user recommendations for each product\nprodRecs = model.recommendForAllItems(10)"],"metadata":{},"outputs":[],"execution_count":22},{"cell_type":"code","source":["training.head(10)"],"metadata":{},"outputs":[],"execution_count":23},{"cell_type":"code","source":["## A function is created which takes userId as input and gives the Top 10\n## recommended products to the user and show’s user’s actual purchase. It also\n## shows the predicted rating for the product which nearly matches with the actual\n## rating.\n"],"metadata":{},"outputs":[],"execution_count":24},{"cell_type":"code","source":["user_test = 33739\ntest_user_recs = userRecs.where(col('user') == user_test).collect()\nprint(test_user_recs)"],"metadata":{},"outputs":[],"execution_count":25},{"cell_type":"code","source":[""],"metadata":{},"outputs":[],"execution_count":26}],"metadata":{"name":"MlibNew","notebookId":1879698768322425},"nbformat":4,"nbformat_minor":0}
