{"cells":[{"cell_type":"code","source":["from numpy import array\nfrom math import sqrt\nfrom pyspark.mllib.clustering import KMeans, KMeansModel\nfrom pyspark.ml.clustering import KMeans\nfrom pyspark.ml.feature import StandardScaler\nfrom pyspark.ml.linalg import Vectors\nfrom pyspark.ml.feature import VectorAssembler\nfrom pyspark.mllib.classification import SVMWithSGD, SVMModel\nfrom pyspark.mllib.regression import LabeledPoint\nimport pandas as pd\nfrom pyspark.sql.functions import udf\nfrom pandas import pivot_table\nfrom pyspark.ml.classification import LogisticRegression\nfrom pyspark.ml.regression import LinearRegression\nfrom pyspark.ml.classification import NaiveBayes\nfrom pyspark.ml.evaluation import MulticlassClassificationEvaluator\nfrom pyspark.sql.types import StructType, StructField, IntegerType, StringType, BooleanType"],"metadata":{},"outputs":[],"execution_count":1},{"cell_type":"code","source":["spark_df = sqlContext.read.format('csv').options(header='true', inferSchema = True).load('/FileStore/tables/ecommerce.csv')\n#spark_df = spark.read.csv('/FileStore/tables/', header=True, schema=sc);\n\ndata = pd.read_csv('/dbfs/FileStore/tables/ecommerce.csv', encoding = \"ISO-8859-1\")\n\n#data = spark.read.csv('/FileStore/tables/newdata.csv', header=True, schema=sc)"],"metadata":{},"outputs":[],"execution_count":2},{"cell_type":"code","source":["spark_df.printSchema()"],"metadata":{},"outputs":[],"execution_count":3},{"cell_type":"code","source":["def get_hash(x):\n  return abs(hash(x)) % 10**9\n\nspark_df = udf(lambda z: get_hash(z), FloatType())\nspark_df['id'] = spark_df['id'].apply(get_hash)"],"metadata":{},"outputs":[],"execution_count":4},{"cell_type":"code","source":["from pyspark.ml import Pipeline\nfrom pyspark.ml.feature import OneHotEncoder, StringIndexer, VectorAssembler\n\ncols = data.columns\nstages = []\n# Assemble our attributes into one column using Vector Assembler\nnumericCols = [\"id\",\"username\"]\nlabelString = StringIndexer(inputCol = \"rating\", outputCol = \"label\").setHandleInvalid(\"keep\")\nstages += [labelString]\n\n\nassemblercols = ['rating']\nassembler = VectorAssembler(inputCols=assemblercols, outputCol=\"features\")\nstages += [assembler]\n\n# Create a Pipeline.\npipeline = Pipeline(stages=stages)\n# Run the feature transformations.\n#  - fit() computes feature statistics as needed.\n#  - transform() actually transforms the features.\npipelineModel = pipeline.fit(data)\n\ndata = pipelineModel.transform(data)\n# Keep relevant columns\nselectedcols = [\"label\", \"features\"] + cols\ndata = data.select(selectedcols) \n\n\ndisplay(data)"],"metadata":{},"outputs":[],"execution_count":5},{"cell_type":"code","source":[""],"metadata":{},"outputs":[],"execution_count":6}],"metadata":{"name":"Clustering_NaiveBayes","notebookId":104905498536558},"nbformat":4,"nbformat_minor":0}
